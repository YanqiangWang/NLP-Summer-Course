{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作业任务：\n",
    "\n",
    "使用98年人民日报语料库进行中文分词训练及测试。\n",
    "\n",
    "### 作业输入：\n",
    "\n",
    "98年人民日报语料库（1998-01-105-带音.txt），用80%的数据作为训练集，20%的数据作为验证集。\n",
    "\n",
    "### 运行环境：\n",
    "\n",
    "Jupyter Notebook, Python3\n",
    "\n",
    "### 作业方法：\n",
    "\n",
    "实现了前向匹配算法的分词功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作业步骤：\n",
    "\n",
    "1.处理语料库: 删除段前标号，以及词性标注。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取原始语料文件\n",
    "in_path = '1998-01-105-带音.txt'\n",
    "file = open(in_path, encoding='gbk')\n",
    "in_data = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理后的语料库\n",
    "curpus_path = 'curpus.txt'\n",
    "curpusfile = open(curpus_path, 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除段前标号,[],{},词性标注(最短匹配)\n",
    "for sentence in in_data:\n",
    "    words = sentence.strip().split(' ')\n",
    "    words.pop(0)\n",
    "    \n",
    "    for word in words:\n",
    "        if word.strip() != '':\n",
    "            if word.startswith('['):\n",
    "                word = word[1:]\n",
    "            elif ']' in word:\n",
    "                word = word[0:word.index(']')]\n",
    "                \n",
    "            if '{' in word:\n",
    "                word = word[0:word.index('{')]\n",
    "\n",
    "            w_c = word.split('/')\n",
    "            # 生成语料库\n",
    "            curpusfile.write(w_c[0] + ' ')\n",
    "            \n",
    "    curpusfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.随机划分训练集80%和验证集20%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 随机划分\n",
    "curpus = open(curpus_path, encoding='utf-8').readlines()\n",
    "train_data, test_data = train_test_split(\n",
    "    curpus, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22787\n",
      "0.7999736691973494\n",
      "0.20002633080265064\n"
     ]
    }
   ],
   "source": [
    "# 查看划分后的数据大小\n",
    "print(len(curpus))\n",
    "print(len(train_data) / len(curpus))\n",
    "print(len(test_data) / len(curpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.前向匹配算法FMM的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1176a89742d64944af724ee3a6a3ce7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18229), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成词典\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "dic = []\n",
    "\n",
    "for sentence in tqdm_notebook(train_data):\n",
    "    words = sentence.strip().split(' ')\n",
    "    for word in words:\n",
    "        if word.strip() != '':\n",
    "            if word not in dic:\n",
    "                dic.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置单词最大长度\n",
    "max_dic_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成分词测试文本\n",
    "test_text = []\n",
    "for sentence in test_data:\n",
    "    words = sentence.strip().split(' ')\n",
    "    test_text.append(''.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存验证集\n",
    "test_path = 'test.txt'\n",
    "testfile = open(test_path, 'w', encoding='utf-8')\n",
    "for sentence in test_data:\n",
    "    testfile.write(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存分词结果\n",
    "result_path = 'result.txt'\n",
    "resultfile = open(result_path, 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6802794fc12f4ca0a1e41ab06ffbfd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4558), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 前向匹配\n",
    "for sentence in tqdm_notebook(test_text):\n",
    "    sent = sentence\n",
    "    words = []\n",
    "    max_len = max_dic_len\n",
    "    while(len(sent) > 0):\n",
    "        word_len = max_len\n",
    "        for i in range(0, max_len):\n",
    "            word = sent[0:word_len]\n",
    "            if word_len == 1 or word in dic:\n",
    "                sent = sent[word_len:]\n",
    "                words.append(word)\n",
    "                word = []\n",
    "                break\n",
    "            else:\n",
    "                word_len -= 1\n",
    "                word = []\n",
    "    resultfile.write(' '.join(words) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能评价\n",
    "\n",
    "查准率，查全率，F度量\n",
    "\n",
    "Precision = (Number of words correctly segmented) / (Number of words segmented) * 100%\n",
    "\n",
    "Recall = (Number of words correctly segmented) / (Number of words in the reference) * 100%\n",
    "\n",
    "F measure = 2 * P * R / (P + R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339c56787f4e4d8c8c93c29231e27223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4527), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_word(path):\n",
    "    f = open(path, 'r', encoding='utf-8')\n",
    "    lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "result_lines = get_word(result_path)\n",
    "test_lines = get_word(test_path)\n",
    "\n",
    "list_num = len(test_lines) if len(test_lines) < len(result_lines) else len(result_lines)\n",
    "right_num = 0\n",
    "result_cnt = 0\n",
    "test_cnt = 0\n",
    "\n",
    "for i in tqdm_notebook(range(list_num)):\n",
    "    result_sent = list(result_lines[i].split())\n",
    "    test_sent = list(test_lines[i].split())\n",
    "    \n",
    "    result_cnt += len(result_sent)\n",
    "    test_cnt += len(test_sent)\n",
    "    \n",
    "    str_result = ''\n",
    "    str_test = ''\n",
    "    \n",
    "    i_result = 0\n",
    "    i_test = 0\n",
    "    \n",
    "    while i_result < len(result_sent) and i_test < len(test_sent):\n",
    "        word_result = result_sent[i_result]\n",
    "        word_test = test_sent[i_test]\n",
    "        \n",
    "        str_result += word_result\n",
    "        str_test += word_test\n",
    "        \n",
    "        if word_result == word_test:\n",
    "            right_num += 1\n",
    "            i_result += 1\n",
    "            i_test += 1\n",
    "        \n",
    "        else:\n",
    "            while len(str_result) > len(str_test):\n",
    "                i_test += 1\n",
    "                if i_test >= len(test_sent):\n",
    "                    break\n",
    "                str_test += test_sent[i_test]\n",
    "            \n",
    "            while len(str_result) < len(str_test):\n",
    "                i_result += 1\n",
    "                if i_result >= len(result_sent):\n",
    "                    break\n",
    "                str_result += result_sent[i_result]\n",
    "            \n",
    "            i_test += 1\n",
    "            i_result += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成结果词的个数： 227640\n",
      "验证集结果词个数： 219680\n",
      "查准率： 0.8301748374626603\n",
      "查全率： 0.8602558266569555\n",
      "F度量： 0.8449476884556917\n"
     ]
    }
   ],
   "source": [
    "print(\"生成结果词的个数：\", result_cnt)\n",
    "print(\"验证集结果词个数：\", test_cnt)\n",
    "\n",
    "p = right_num / result_cnt\n",
    "r = right_num / test_cnt\n",
    "f = 2 * p * r / (p + r)\n",
    "\n",
    "print(\"查准率：\", p)\n",
    "print(\"查全率：\", r)\n",
    "print(\"F度量：\", f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
